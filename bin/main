#!/usr/bin/env python3
"""
ANavS Keelson Connector

This connector reads ANavS binary protocol data and publishes it via Keelson/Zenoh.
It can connect directly to an ANavS device via TCP or read from stdin.

Usage:
    # Connect to ANavS device directly:
    python3 anavs_connector.py -e vessel_name
    
    # Read from stdin (e.g., from socat):
    socat TCP:192.168.1.124:6001 STDOUT | python3 anavs_connector.py --input-mode stdin -e vessel_name
"""

import zenoh
import logging
import warnings
import json
import time
import keelson
import sys
import socket
import struct
import select
from datetime import datetime, timedelta
import pytz
from terminal_inputs import terminal_inputs
from keelson.payloads.Primitives_pb2 import TimestampedBytes, TimestampedInt, TimestampedFloat, TimestampedString, TimestampedTimestamp
from keelson.payloads.foxglove.LocationFix_pb2 import LocationFix
from keelson.payloads.Decomposed3DVector_pb2 import Decomposed3DVector

# ANavS Binary Protocol Constants
SYNC_CHAR_1 = 0xB5
SYNC_CHAR_2 = 0x62
CLASS_ID = 0x02
MESSAGE_ID = 0xE0

def fletcher_checksum(data):
    """Calculate Fletcher-16 checksum with modulo 256 as per ANavS spec."""
    # Optimized version using memoryview for better performance
    view = memoryview(data)
    ck_a = ck_b = 0
    for byte in view:
        ck_a = (ck_a + byte) & 0xFF  # Bitwise AND is faster than modulo
        ck_b = (ck_b + ck_a) & 0xFF
    return ck_a, ck_b

def parse_anavs_binary(data_buffer):
    """Parse ANavS binary protocol messages from a data buffer.
    
    Returns: (consumed_bytes, messages_list)
    Where messages_list contains decoded position data dictionaries.
    """
    messages = []
    consumed = 0
    buffer_len = len(data_buffer)
    
    # Pre-compile struct format for header parsing - this is safe
    header_struct = struct.Struct('<BBBBH')
    checksum_struct = struct.Struct('<BB')
    
    while consumed + 8 <= buffer_len:  # Minimum message size
        # Look for sync pattern
        sync_pos = -1
        for i in range(consumed, buffer_len - 1):
            if data_buffer[i] == SYNC_CHAR_1 and data_buffer[i + 1] == SYNC_CHAR_2:
                sync_pos = i
                break
        
        if sync_pos == -1:
            # No sync found, consume all but last byte
            consumed = max(0, buffer_len - 1)
            break
            
        # Skip any bytes before sync
        consumed = sync_pos
            
        # Check if we have enough bytes for header
        remaining = buffer_len - consumed
        if remaining < 6:
            break
            
        # Parse header using pre-compiled struct
        try:
            sync1, sync2, msg_class, msg_id, length = header_struct.unpack(
                data_buffer[consumed:consumed+6]
            )
        except struct.error as e:
            logging.warning(f"Header unpack error: {e}, buffer len: {remaining}")
            consumed += 2
            continue
        
        # Validate header
        if sync1 != SYNC_CHAR_1 or sync2 != SYNC_CHAR_2 or msg_class != CLASS_ID or msg_id != MESSAGE_ID:
            consumed += 2
            continue
            
        # Check if we have complete message
        total_msg_len = 6 + length + 2  # header + payload + checksum
        if remaining < total_msg_len:
            break
            
        # Extract payload and checksum
        payload_start = consumed + 6
        payload_end = payload_start + length
        payload = data_buffer[payload_start:payload_end]
        checksum = data_buffer[payload_end:payload_end+2]
        
        # Verify checksum
        checksum_data = data_buffer[consumed+2:payload_end]  # class + id + length + payload
        expected_ck_a, expected_ck_b = fletcher_checksum(checksum_data)
        received_ck_a, received_ck_b = checksum_struct.unpack(checksum)
        
        if expected_ck_a != received_ck_a or expected_ck_b != received_ck_b:
            logging.warning(f"Checksum mismatch: expected {expected_ck_a:02x}{expected_ck_b:02x}, got {received_ck_a:02x}{received_ck_b:02x}")
            consumed += 2
            continue
            
        # Parse payload
        try:
            pos_data = parse_anavs_payload(payload)
            if pos_data:
                messages.append(pos_data)
                logging.debug(f"Successfully parsed ANavS message, payload length: {length}")
        except Exception as e:
            logging.warning(f"Failed to parse payload: {e}")
            
        # Consume this message
        consumed += total_msg_len
        
    return consumed, messages

def parse_anavs_payload(payload):
    """Parse ANavS binary payload to extract position, velocity, acceleration, and attitude data."""
    if len(payload) < 170:  # Minimum payload size for extended data
        return None
        
    try:
        # Parse according to ANavS binary format specification
        offset = 0
        
        # id (uint8)
        msg_id = struct.unpack('<B', payload[offset:offset+1])[0]
        offset += 1
        
        # resCode (uint16)
        res_code = struct.unpack('<H', payload[offset:offset+2])[0]
        offset += 2
        
        # week (uint16)
        week = struct.unpack('<H', payload[offset:offset+2])[0]
        offset += 2
        
        # tow (double)
        tow = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # weekInit (uint16)
        week_init = struct.unpack('<H', payload[offset:offset+2])[0]
        offset += 2
        
        # towInit (double)
        tow_init = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # reserved (int16)
        offset += 2
        
        # lat (double)
        lat = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # lon (double)
        lon = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # height (double)
        height = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # ECEF-X (double)
        ecef_x = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # ECEF-Y (double)
        ecef_y = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # ECEF-Z (double)
        ecef_z = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # b - Baseline in NED frame (3*double)
        baseline_n = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        baseline_e = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        baseline_d = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # bStdDev - Standard deviation of baseline (3*double)
        baseline_std_n = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        baseline_std_e = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        baseline_std_d = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # vel - Velocity in NED frame (3*double)
        vel_n = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        vel_e = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        vel_d = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # velStdDev - Standard deviation of velocity (3*double)
        vel_std_n = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        vel_std_e = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        vel_std_d = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # acc - Acceleration in body frame (3*double)
        acc_x = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        acc_y = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        acc_z = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # accStdDev - Standard deviation of acceleration (3*double)
        acc_std_x = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        acc_std_y = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        acc_std_z = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # att - Attitude/Euler angles in degrees (heading, pitch, roll) (3*double)
        heading = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        pitch = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        roll = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # attStdDev - Standard deviation of attitude (3*double)
        att_std_heading = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        att_std_pitch = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        att_std_roll = struct.unpack('<d', payload[offset:offset+8])[0]
        offset += 8
        
        # Convert GPS time to UTC datetime
        # GPS epoch is January 6, 1980
        gps_epoch = datetime(1980, 1, 6, tzinfo=pytz.utc)
        gps_seconds = week * 7 * 24 * 3600 + tow
        message_timestamp = gps_epoch + timedelta(seconds=gps_seconds)
        utc_timestamp = message_timestamp  # GPS time is already in UTC (with leap seconds)
        
        return {
            'msg_id': msg_id,
            'res_code': res_code,
            'week': week,
            'tow': tow,
            'lat': lat,
            'lon': lon,
            'height': height,
            'ecef_x': ecef_x,
            'ecef_y': ecef_y,
            'ecef_z': ecef_z,
            'baseline': [baseline_n, baseline_e, baseline_d],
            'baseline_std': [baseline_std_n, baseline_std_e, baseline_std_d],
            'velocity_ned': [vel_n, vel_e, vel_d],
            'velocity_std': [vel_std_n, vel_std_e, vel_std_d],
            'acceleration_body': [acc_x, acc_y, acc_z],
            'acceleration_std': [acc_std_x, acc_std_y, acc_std_z],
            'attitude': [heading, pitch, roll],
            'attitude_std': [att_std_heading, att_std_pitch, att_std_roll],
            'timestamp': message_timestamp,
            'utc_timestamp': utc_timestamp
        }
        
    except struct.error as e:
        logging.warning(f"Struct unpacking error: {e}")
        return None
    except IndexError as e:
        logging.warning(f"Payload too short for extended parsing: {e}")
        return None

def create_tcp_connection(host, port):
    """Create TCP connection to ANavS device."""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(10.0)  # 10 second timeout
        sock.connect((host, port))
        sock.settimeout(1.0)   # 1 second timeout for reads
        logging.info(f"Connected to ANavS device at {host}:{port}")
        return sock
    except Exception as e:
        logging.error(f"Failed to connect to ANavS device: {e}")
        return None

def main():
    # Input arguments and configurations
    args = terminal_inputs()
    
    # Setup logger
    logging.basicConfig(
        format="%(asctime)s %(levelname)s %(name)s :%(lineno)d %(message)s", 
        level=args.log_level
    )
    logging.captureWarnings(True)
    warnings.filterwarnings("once")

    ## Construct session
    logging.info("Opening Zenoh session...")
    zenoh.init_log_from_env_or("error")

    conf = zenoh.Config()
    if args.connect is not None:
        conf.insert_json5("connect/endpoints", json.dumps(args.connect))
    
    with zenoh.open(conf) as session:
        logging.info("Zenoh session opened.")

        #################################################
        # Setting up PUBLISHERS

        # RAW binary data publisher
        key_exp_pub_raw = keelson.construct_pubsub_key(
            base_path=args.realm,
            entity_id=args.entity_id,
            subject="raw",  
            source_id=args.source_id + "/binary",
        )
        pub_raw = session.declare_publisher(
            key_exp_pub_raw, congestion_control=zenoh.CongestionControl.DROP
        )
        logging.info(f"Created RAW publisher: {key_exp_pub_raw}")

        # Pre-compile all other key expressions for performance
        key_expressions = {}
        
        if any(topic in args.publish for topic in ("location_fix", "all")):
            key_expressions['location_fix'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="location_fix", 
                source_id=args.source_id,
            )
            
        if any(topic in args.publish for topic in ("velocity", "all")):
            key_expressions['velocity'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="ned_velocity_mps", 
                source_id=args.source_id,
            )
            
        if any(topic in args.publish for topic in ("acceleration", "all")):
            key_expressions['acceleration'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="linear_acceleration_mpss", 
                source_id=args.source_id + "/body_frame",
            )
            
        if any(topic in args.publish for topic in ("attitude", "all")):
            key_expressions['heading'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="heading_true_north_deg", 
                source_id=args.source_id,
            )
            key_expressions['pitch'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="pitch_deg", 
                source_id=args.source_id,
            )
            key_expressions['roll'] = keelson.construct_pubsub_key(
                base_path=args.realm,
                entity_id=args.entity_id,
                subject="roll_deg", 
                source_id=args.source_id,
            )

        #################################################
        # Setup input stream

        tcp_socket = None
        
        if args.input_mode == "tcp":
            tcp_socket = create_tcp_connection(args.anavs_host, args.anavs_port)
            if tcp_socket is None:
                logging.error("Failed to connect to ANavS device, exiting")
                sys.exit(1)
        else:
            logging.info("Reading from stdin")

        #################################################
        # Main processing loop

        binary_buffer = bytearray()
        chunk_size = 8192  # Increased buffer size for better performance
        max_buffer_size = 32768  # Reduced max buffer size
        
        try:
            while True:
                # Read data with optimized chunk size
                if args.input_mode == "tcp" and tcp_socket:
                    try:
                        chunk = tcp_socket.recv(chunk_size)
                        if not chunk:
                            logging.warning("TCP connection closed by remote")
                            break
                    except socket.timeout:
                        continue
                    except Exception as e:
                        logging.error(f"TCP read error: {e}")
                        break
                else:
                    # Non-blocking read from stdin with proper buffering
                    if select.select([sys.stdin], [], [], 0) == ([sys.stdin], [], []):
                        chunk = sys.stdin.buffer.read(chunk_size)
                        if not chunk:
                            continue
                    else:
                        continue
                
                ingress_timestamp = time.time_ns()
                
                # Add to binary buffer
                binary_buffer.extend(chunk)
                
                # Publish RAW message if requested
                if any(topic in args.publish for topic in ("raw", "all")):
                    payload = TimestampedBytes()
                    payload.timestamp.FromNanoseconds(ingress_timestamp)
                    payload.value = chunk
                    serialized_payload = payload.SerializeToString()
                    envelope = keelson.enclose(serialized_payload)
                    pub_raw.put(envelope)
                    logging.debug(f"Published RAW data on {key_exp_pub_raw}")
                
                # Try to parse ANavS binary messages
                try:
                    consumed, messages = parse_anavs_binary(binary_buffer)
                    if consumed > 0:
                        binary_buffer = binary_buffer[consumed:]
                        
                    for pos_data in messages:
                        logging.debug(f"Decoded position: lat={pos_data['lat']:.6f}, lon={pos_data['lon']:.6f}, height={pos_data['height']:.2f}")
                        logging.debug(f"Velocity NED: N={pos_data['velocity_ned'][0]:.3f}, E={pos_data['velocity_ned'][1]:.3f}, D={pos_data['velocity_ned'][2]:.3f} m/s")
                        logging.debug(f"Acceleration Body: X={pos_data['acceleration_body'][0]:.3f}, Y={pos_data['acceleration_body'][1]:.3f}, Z={pos_data['acceleration_body'][2]:.3f} m/s²")
                        logging.debug(f"Attitude: Heading={pos_data['attitude'][0]:.2f}°, Pitch={pos_data['attitude'][1]:.2f}°, Roll={pos_data['attitude'][2]:.2f}°")
                        logging.debug(f"UTC Time: {pos_data['utc_timestamp'].strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]} UTC")
                        
                        message_timestamp = pos_data['timestamp']
                        utc_timestamp = pos_data['utc_timestamp']
                        
                        # Publish LocationFix
                        if any(topic in args.publish for topic in ("location_fix", "all")) and 'location_fix' in key_expressions:
                            payload_location = LocationFix()
                            payload_location.timestamp.FromDatetime(message_timestamp)
                            payload_location.latitude = pos_data['lat']
                            payload_location.longitude = pos_data['lon']
                            payload_location.altitude = pos_data['height']
                            
                            serialized_payload = payload_location.SerializeToString()
                            envelope = keelson.enclose(serialized_payload)
                            session.put(
                                key_expr=key_expressions['location_fix'],
                                payload=envelope,
                                priority=zenoh.Priority.INTERACTIVE_HIGH,
                                congestion_control=zenoh.CongestionControl.DROP,
                            )
                            logging.debug(f"Published LocationFix on {key_expressions['location_fix']}")

                        # Publish Velocity NED - Binary solution velocity (default) = fused GNSS+IMU (Kalman Filter output)
                        if any(topic in args.publish for topic in ("velocity", "all")) and 'velocity' in key_expressions:
                            payload_vel = Decomposed3DVector()
                            payload_vel.timestamp.FromDatetime(message_timestamp)
                            payload_vel.vector.x = pos_data['velocity_ned'][1]  # East
                            payload_vel.vector.y = pos_data['velocity_ned'][0]  # North
                            payload_vel.vector.z = -pos_data['velocity_ned'][2]  # Up (negated down)

                            serialized_payload = payload_vel.SerializeToString()
                            envelope = keelson.enclose(serialized_payload)
                            session.put(
                                key_expr=key_expressions['velocity'],
                                payload=envelope,
                                priority=zenoh.Priority.INTERACTIVE_HIGH,
                                congestion_control=zenoh.CongestionControl.DROP,
                            )
                            logging.debug(f"Published Velocity on {key_expressions['velocity']}")

                        # Publish Acceleration Body Frame
                        if any(topic in args.publish for topic in ("acceleration", "all")) and 'acceleration' in key_expressions:
                            payload_acc = Decomposed3DVector()
                            payload_acc.timestamp.FromDatetime(message_timestamp)
                            payload_acc.vector.x = pos_data['acceleration_body'][0]  # X
                            payload_acc.vector.y = pos_data['acceleration_body'][1]  # Y
                            payload_acc.vector.z = pos_data['acceleration_body'][2]  # Z

                            serialized_payload = payload_acc.SerializeToString()
                            envelope = keelson.enclose(serialized_payload)
                            session.put(
                                key_expr=key_expressions['acceleration'],
                                payload=envelope,
                                priority=zenoh.Priority.INTERACTIVE_HIGH,
                                congestion_control=zenoh.CongestionControl.DROP,
                            )
                            logging.debug(f"Published Body Acceleration on {key_expressions['acceleration']}")

                        # Publish Attitude (Euler angles)
                        if any(topic in args.publish for topic in ("attitude", "all")):
                            # Publish heading separately with specific subject name
                            if 'heading' in key_expressions:
                                payload_heading = TimestampedFloat()
                                payload_heading.timestamp.FromDatetime(message_timestamp)
                                payload_heading.value = pos_data['attitude'][0]  # heading
                                
                                serialized_payload = payload_heading.SerializeToString()
                                envelope = keelson.enclose(serialized_payload)
                                session.put(
                                    key_expr=key_expressions['heading'],
                                    payload=envelope,
                                    priority=zenoh.Priority.INTERACTIVE_HIGH,
                                    congestion_control=zenoh.CongestionControl.DROP,
                                )
                                logging.debug(f"Published Heading on {key_expressions['heading']}")
                            
                            # Publish pitch and roll
                            if 'pitch' in key_expressions:
                                payload_pitch = TimestampedFloat()
                                payload_pitch.timestamp.FromDatetime(message_timestamp)
                                payload_pitch.value = pos_data['attitude'][1]  # pitch
                                
                                serialized_payload = payload_pitch.SerializeToString()
                                envelope = keelson.enclose(serialized_payload)
                                session.put(
                                    key_expr=key_expressions['pitch'],
                                    payload=envelope,
                                    priority=zenoh.Priority.INTERACTIVE_HIGH,
                                    congestion_control=zenoh.CongestionControl.DROP,
                                )
                                logging.debug(f"Published Pitch on {key_expressions['pitch']}")
                            
                            if 'roll' in key_expressions:
                                payload_roll = TimestampedFloat()
                                payload_roll.timestamp.FromDatetime(message_timestamp)
                                payload_roll.value = pos_data['attitude'][2]  # roll
                                
                                serialized_payload = payload_roll.SerializeToString()
                                envelope = keelson.enclose(serialized_payload)
                                session.put(
                                    key_expr=key_expressions['roll'],
                                    payload=envelope,
                                    priority=zenoh.Priority.INTERACTIVE_HIGH,
                                    congestion_control=zenoh.CongestionControl.DROP,
                                )
                                logging.debug(f"Published Roll on {key_expressions['roll']}")

        
                        
                except Exception as e:
                    logging.warning(f"Binary parsing error: {e}")
                    # Clear some buffer to prevent repeated errors
                    if len(binary_buffer) > 1000:
                        binary_buffer = binary_buffer[100:]
                
                # Prevent buffer from growing too large - optimized threshold
                if len(binary_buffer) > max_buffer_size:
                    # Keep only the last portion
                    binary_buffer = binary_buffer[-max_buffer_size//2:]
                    logging.warning("Binary buffer overflow, truncating")
                    
        except KeyboardInterrupt:
            logging.info("Interrupted by user")
        except Exception as e:
            logging.error(f"Unexpected error: {e}")
        finally:
            if tcp_socket:
                tcp_socket.close()
                logging.info("TCP connection closed")

    logging.info("Zenoh session closed.")
    sys.exit(0)

if __name__ == "__main__":
    main()
